{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f6c736f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'matplotlib' has no attribute 'rcParams'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mglob\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\matplotlib\\pyplot.py:56\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcycler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cycler\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\n\u001b[1;32m---> 56\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolorbar\u001b[39;00m\n\u001b[0;32m     57\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\matplotlib\\colorbar.py:19\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook, collections, cm, colors, contour, ticker\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmartist\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpatches\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpatches\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\matplotlib\\collections.py:20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (_api, _path, artist, cbook, cm, colors \u001b[38;5;28;01mas\u001b[39;00m mcolors, _docstring,\n\u001b[0;32m     21\u001b[0m                hatch \u001b[38;5;28;01mas\u001b[39;00m mhatch, lines \u001b[38;5;28;01mas\u001b[39;00m mlines, path \u001b[38;5;28;01mas\u001b[39;00m mpath, transforms)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_enums\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m JoinStyle, CapStyle\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# \"color\" is excluded; it is a compound setter, and its docstring differs\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# in LineCollection.\u001b[39;00m\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\matplotlib\\artist.py:16\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcolors\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BoundaryNorm\n\u001b[1;32m---> 16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ScalarMappable\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (BboxBase, Bbox, IdentityTransform, Transform, TransformedBbox,\n\u001b[0;32m     19\u001b[0m                          TransformedPatchPath, TransformedPath)\n",
      "File \u001b[1;32m~\\.conda\\envs\\myenv\\lib\\site-packages\\matplotlib\\cm.py:29\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m datad\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_cm_listed\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cmaps \u001b[38;5;28;01mas\u001b[39;00m cmaps_listed\n\u001b[1;32m---> 29\u001b[0m _LUTSIZE \u001b[38;5;241m=\u001b[39m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrcParams\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage.lut\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_gen_cmap_registry\u001b[39m():\n\u001b[0;32m     33\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;124;03m    Generate a dict mapping standard colormap names to standard colormaps, as\u001b[39;00m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;124;03m    well as the reversed colormaps.\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'matplotlib' has no attribute 'rcParams'"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from PIL import Image\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.layers import Input, Reshape, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import LeakyReLU, ReLU, PReLU\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose\n",
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "%matplotlib inline\n",
    "print(\"Import Libraries...................Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "473cd28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(data_dir):\n",
    "    images = list()\n",
    "    for file_name in glob.glob(data_dir + '/*.jpg'):\n",
    "        img = image.load_img(file_name)\n",
    "        img = image.img_to_array(img)\n",
    "        images.append(img) \n",
    "    return np.asarray(images) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44b3ba95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_generator(latent_dim):\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    model = Sequential(name='generator')\n",
    "\n",
    "    model.add(Dense(4 * 4 * 1024, kernel_initializer=init, input_dim=latent_dim))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "    model.add(Reshape((4, 4, 1024)))\n",
    "\n",
    "    model.add(Conv2DTranspose(512, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2DTranspose(256, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2DTranspose(128, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(ReLU())\n",
    "\n",
    "    model.add(Conv2DTranspose(3, kernel_size=3, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(Activation('tanh'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7092fa12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_discriminator(image_shape=(64,64,3)):\n",
    "\n",
    "    init = tf.keras.initializers.RandomNormal(stddev=0.02)\n",
    "    model = Sequential(name='discriminator')\n",
    "\n",
    "    model.add(Conv2D(64, kernel_size=3, strides=2, padding='same', input_shape=image_shape, kernel_initializer=init))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(256, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Conv2D(512, kernel_size=5, strides=2, padding='same', kernel_initializer=init))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(1, kernel_initializer=init))\n",
    "    model.add(Activation('sigmoid'))\n",
    "\n",
    "    model.summary()\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b6f0856",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Cross entropy\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m cross_entropy \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mBinaryCrossentropy()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Cross entropy\n",
    "cross_entropy = tf.keras.losses.BinaryCrossentropy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5402adff",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DCGAN(Model):\n",
    "    def __init__(self, discriminator, generator, latent_dim):\n",
    "        super(DCGAN, self).__init__()\n",
    "        self.discriminator = discriminator\n",
    "        self.generator = generator\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def compile(self, d_optimizer, g_optimizer):\n",
    "        super(DCGAN,self).compile()\n",
    "        self.d_optimizer = d_optimizer\n",
    "        self.g_optimizer = g_optimizer\n",
    "        self.d_loss_metric = keras.metrics.Mean(name='d_loss')\n",
    "        self.g_loss_metric = keras.metrics.Mean(name='g_loss')\n",
    "\n",
    "    def generator_loss(self, fake_output):\n",
    "        return cross_entropy(tf.ones_like(fake_output), fake_output)\n",
    "\n",
    "    def discriminator_loss(self, real_output, fake_output):\n",
    "        real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
    "        fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
    "        total_loss = real_loss + fake_loss\n",
    "        return total_loss\n",
    "\n",
    "    @tf.function\n",
    "    def train_step(self, real_images):\n",
    "        batch_size = tf.shape(real_images)[0]\n",
    "        random_latent_vectors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        with tf.GradientTape() as discriminator_tape:\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            real_output = self.discriminator(real_images)\n",
    "            fake_output = self.discriminator(generated_images)\n",
    "            d_loss = self.discriminator_loss(real_output, fake_output)\n",
    "        discriminator_grads = discriminator_tape.gradient(d_loss, self.discriminator.trainable_weights)\n",
    "        self.d_optimizer.apply_gradients(zip(discriminator_grads, self.discriminator.trainable_weights))\n",
    "\n",
    "        random_latent_vetors = tf.random.normal(shape=(batch_size, self.latent_dim))\n",
    "\n",
    "        with tf.GradientTape() as generator_tape:\n",
    "            generated_images = self.generator(random_latent_vectors)\n",
    "            fake_output = self.discriminator(generated_images)\n",
    "            g_loss = self.generator_loss(fake_output)\n",
    "        generator_grads = generator_tape.gradient(g_loss, self.generator.trainable_weights)\n",
    "        self.g_optimizer.apply_gradients(zip(generator_grads, self.generator.trainable_weights))\n",
    "\n",
    "        self.d_loss_metric.update_state(d_loss)\n",
    "        self.g_loss_metric.update_state(g_loss)\n",
    "        return {\n",
    "            'd_loss': self.d_loss_metric.result(),\n",
    "            'g_loss': self.g_loss_metric.result(),\n",
    "        }\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "963c430c-3ebf-498e-8c99-135b08bfcc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GANMonitor(keras.callbacks.Callback):\n",
    "    def __init__(self, num_img=3, latent_dim=128):\n",
    "        self.num_img = num_img\n",
    "        self.latent_dim = latent_dim\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        if epoch % 10 == 0:\n",
    "            random_latent_vectors = tf.random.normal(shape=(self.num_img, self.latent_dim))\n",
    "            generated_images = self.model.generator(random_latent_vectors)\n",
    "            fig = plt.figure(figsize=(10, 4))\n",
    "            for i in range(self.num_img):\n",
    "                plt.subplot(2, 5, i + 1)\n",
    "                plt.imshow(generated_images[i,:,:,:] * 0.5 + 0.5)\n",
    "                plt.axis('off')\n",
    "            plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5da3f05a-b43d-47bc-8c0e-a7d296cf582e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_17 (Dense)            (None, 16384)             2113536   \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 16384)            65536     \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_30 (ReLU)             (None, 16384)             0         \n",
      "                                                                 \n",
      " reshape_9 (Reshape)         (None, 4, 4, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_transpose_28 (Conv2D  (None, 8, 8, 512)        13107712  \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 8, 8, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_31 (ReLU)             (None, 8, 8, 512)         0         \n",
      "                                                                 \n",
      " conv2d_transpose_29 (Conv2D  (None, 16, 16, 256)      3277056   \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 16, 16, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_32 (ReLU)             (None, 16, 16, 256)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_30 (Conv2D  (None, 32, 32, 128)      819328    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 32, 32, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " re_lu_33 (ReLU)             (None, 32, 32, 128)       0         \n",
      "                                                                 \n",
      " conv2d_transpose_31 (Conv2D  (None, 64, 64, 3)        3459      \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " activation_12 (Activation)  (None, 64, 64, 3)         0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 19,390,211\n",
      "Trainable params: 19,355,651\n",
      "Non-trainable params: 34,560\n",
      "_________________________________________________________________\n",
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_22 (Conv2D)          (None, 32, 32, 64)        1792      \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 32, 32, 64)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 16, 16, 128)       73856     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 16, 16, 128)      512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 16, 16, 128)       0         \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 8, 8, 256)         819456    \n",
      "                                                                 \n",
      " batch_normalization_50 (Bat  (None, 8, 8, 256)        1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 8, 8, 256)         0         \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 4, 4, 512)         3277312   \n",
      "                                                                 \n",
      " batch_normalization_51 (Bat  (None, 4, 4, 512)        2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " leaky_re_lu_25 (LeakyReLU)  (None, 4, 4, 512)         0         \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 8192)              0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 1)                 8193      \n",
      "                                                                 \n",
      " activation_13 (Activation)  (None, 1)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,184,193\n",
      "Trainable params: 4,182,401\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "latent_dim = 128\n",
    "generator = build_generator(latent_dim)\n",
    "discriminator = build_discriminator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "51137636-47f8-4da6-8a65-0675bf879446",
   "metadata": {},
   "outputs": [],
   "source": [
    "gan = DCGAN(discriminator=discriminator, generator=generator, latent_dim=latent_dim)\n",
    "gan.compile(\n",
    "    d_optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    "    g_optimizer=Adam(learning_rate=0.0002, beta_1=0.5),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1caaeb6d-1981-4019-97b0-bc254f22b0e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15747, 64, 64, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train = read_images('./cats')\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6ee8e2-8a07-4a3c-a103-2b8fe553955c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/GPU:0'):\n",
    "    history = gan.fit(X_train, epochs=50, callbacks=[GANMonitor(num_img=10, latent_dim=latent_dim)])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
